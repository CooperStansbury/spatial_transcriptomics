{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb28b84-0400-4057-b60f-ce3471da1ab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 14:51:26.344290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 14:51:26.459667: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2022-12-12 14:51:26.459689: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-12-12 14:51:26.485094: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-12 14:51:27.168250: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2022-12-12 14:51:27.168332: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2022-12-12 14:51:27.168338: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/cstansbu/git_repositories/spatial_transcriptomics/clustering/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scanpy as sc\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import tabulate\n",
    "import itertools\n",
    "import igraph as ig\n",
    "import matplotlib.patches as mpatches\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import leidenalg as la\n",
    "import dask.array as da\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import umap\n",
    "import bbknn\n",
    "import bbknn.matrix\n",
    "from importlib import reload\n",
    "from scipy import stats\n",
    "import matplotlib.image as mpimg\n",
    "import goatools\n",
    "from goatools.anno.gaf_reader import GafReader\n",
    "import Bio.UniProt.GOA as GOA\n",
    "import gget\n",
    "\n",
    "# locals\n",
    "import utils as ut\n",
    "reload(ut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "776bdc20-afc9-4e6b-8d2e-7ac7abe527d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# load cluster assignments\n",
    "cdf = pd.read_csv(\"clusterAssignments.csv\")\n",
    "cid = {}\n",
    "\n",
    "for key in cdf['key'].unique():\n",
    "    t = cdf[cdf['key'] == key]\n",
    "    cid[key] = t\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bb7263a-935f-404f-9719-aeaf1033708c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "dirPath = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/scanpy/\"\n",
    "\n",
    "adata = {}\n",
    "\n",
    "for f in os.listdir(dirPath):\n",
    "    \n",
    "    if f.endswith('.h5ad'):\n",
    "        key = f.split(\".\")[0]\n",
    "        fullPath = f\"{dirPath}{f}\"\n",
    "        data = sc.read(fullPath)\n",
    "        adata[key] = data\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "040195cb-e5c2-49d8-91e1-9db319426fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done: /nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/cellAssignments/ND.csv\n",
      "done: /nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/cellAssignments/HFD8.csv\n",
      "done: /nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/cellAssignments/HFD14.csv\n"
     ]
    }
   ],
   "source": [
    "keys = ['ND', 'HFD8', 'HFD14']\n",
    "outpath = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/cellAssignments/\"\n",
    "\n",
    "res = []\n",
    "refs = []\n",
    "\n",
    "for key in keys:\n",
    "    data = adata[key]\n",
    "    \n",
    "    # get the run key\n",
    "    allKeys = list(data.obs.keys() )\n",
    "    allKeys.remove('n_genes')\n",
    "    runKey = allKeys[0]\n",
    "    \n",
    "    clusterIds = data.obs[runKey].astype(int) + 1  # note that these are zero-indexed!\n",
    "    clusterIds = pd.DataFrame(clusterIds).reset_index(drop=False)\n",
    "    clusterIds.columns =['barcode', 'clusterId']\n",
    "    \n",
    "    df = data.to_df()\n",
    "    \n",
    "    ctf = pd.DataFrame(df.index)\n",
    "    ctf.columns =['barcode']\n",
    "    ctf = pd.merge(ctf, clusterIds,\n",
    "                   how='left',\n",
    "                   left_on='barcode', \n",
    "                   right_on='barcode')\n",
    "    \n",
    "    cTypes = cid[key][['cellType', 'clusterId']]\n",
    "    \n",
    "    ctf = pd.merge(ctf, cTypes,\n",
    "                   how='left',\n",
    "                   left_on='clusterId', \n",
    "                   right_on='clusterId')\n",
    "    \n",
    "    fpath = f\"{outpath}{key}.csv\"\n",
    "    ctf.to_csv(fpath, index=False)\n",
    "    print(f'done: {fpath}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2a9daf-4c5b-4211-ab5b-17b111a56894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
