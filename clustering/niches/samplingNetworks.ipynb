{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9b3b7-9d1d-404f-be7f-1cf79d60aacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "from scipy import interpolate\n",
    "import os\n",
    "from mpl_toolkits.axes_grid1.anchored_artists import AnchoredSizeBar\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import matplotlib.font_manager as fm\n",
    "import tabulate\n",
    "from scipy.sparse import csgraph\n",
    "import scipy.stats\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from textwrap import wrap\n",
    "from sklearn import metrics\n",
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.neighbors import radius_neighbors_graph\n",
    "import matplotlib.patches as mpatches\n",
    "import sklearn.neighbors\n",
    "from scipy.spatial import distance\n",
    "from skimage.filters import unsharp_mask\n",
    "from skimage.color import rgb2gray\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from collections import Counter\n",
    "import skimage\n",
    "from Bio import SeqIO\n",
    "from Bio.KEGG import REST\n",
    "from Bio.KEGG.KGML import KGML_parser\n",
    "import io\n",
    "import numpy as np\n",
    "import gget\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data, segmentation, feature, future\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from functools import partial\n",
    "import matplotlib\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import utils as ut\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d199e8fc-0737-4a16-bac6-84dcd51bccc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the scale factors\n",
    "\n",
    "keys = ['ND', 'HFD8', 'HFD14']\n",
    "\n",
    "scales = []\n",
    "\n",
    "for key in keys:\n",
    "    path = f\"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/SPT/{key}/outs/spatial/scalefactors_json.json\"\n",
    "    \n",
    "    tmp = pd.read_json(path, lines=True)\n",
    "    tmp['key'] = key\n",
    "    # tmp['lowres_spot_diameter_pixels'] = tmp['spot_diameter_fullres'] * tmp['tissue_lowres_scalef']\n",
    "    # tmp['lowres_spot_diameter_units'] = tmp['lowres_spot_diameter_pixels'] * 65\n",
    "    \n",
    "    scales.append(tmp)\n",
    "    \n",
    "scales = pd.concat(scales, ignore_index=True)\n",
    "print(scales)\n",
    "# print(scales[['key', 'spot_diameter_fullres', 'lowres_spot_diameter_pixels']])\n",
    "\n",
    "\n",
    "\n",
    "def getscalebar(key, length, scales=scales):\n",
    "    \"\"\"Length is physical units \"\"\"\n",
    "    lookup = scales.loc[scales['key'] == key]\n",
    "    pixels = lookup['spot_diameter_fullres'].values[0]\n",
    "    scaleFactor = lookup['tissue_hires_scalef'].values[0]\n",
    "    units = 55 # mircons\n",
    "    fullResPixels = (pixels * length) / units\n",
    "    lowResPixels = fullResPixels * scaleFactor\n",
    "    return lowResPixels\n",
    "\n",
    "def transScaleBar(hiresX, ultrahiresX, lowResPixels):\n",
    "    \"\"\"A function to resize the scale bar based on the \n",
    "    ultra hir-res image shape \"\"\"\n",
    "    newPixels = (lowResPixels * ultrahiresX) / hiresX\n",
    "    return newPixels\n",
    "\n",
    "getscalebar('ND', length=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7603e-0566-4f41-8a35-6835778479aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imDir = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/images/lowres/\"\n",
    "\n",
    "\n",
    "lowres = {}\n",
    "\n",
    "for f in os.listdir(imDir):\n",
    "    if f.endswith(\"png\"):\n",
    "        fullpath = f\"{imDir}{f}\"\n",
    "        img = skimage.io.imread(fullpath, as_gray=True)\n",
    "        key = f.replace(\".png\", \"\")\n",
    "        print(key, img.shape)\n",
    "        lowres[key] = img\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943fc3ca-5029-467a-b194-3edf0898cbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fPath = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/LR/LewisLabUSCS/Mouse/Mouse-2020-Baccin-LR-pairs.xlsx\"\n",
    "\n",
    "lr = pd.read_excel(fPath, engine=\"openpyxl\")\n",
    "print(lr.shape)\n",
    "\n",
    "lr['ligand'] = lr['Ligand.Mouse'].str.upper()\n",
    "lr['receptor'] = lr['Receptor.Mouse'].str.upper()\n",
    "lr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b96055-76bd-4fde-9abb-8f35731a7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardDir =  \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/CARDInputs/\"\n",
    "xyPath =  \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/combinedEmbedding.csv\"\n",
    "xy = pd.read_csv(xyPath)\n",
    "cTypes = sorted(list(xy['cellTypes'].unique()))\n",
    "print(cTypes)\n",
    "print()\n",
    "\n",
    "keys = ['ND', 'HFD8', 'HFD14']\n",
    "\n",
    "rna = {}\n",
    "labels = {}\n",
    "\n",
    "for key in keys:\n",
    "    labelPath = f\"{cardDir}{key}_macrophage_clusters.csv\"\n",
    "    lf = pd.read_csv(labelPath)\n",
    "    \n",
    "    lf = pd.merge(lf, xy[['x', 'y', 'cellId', 'colors']], \n",
    "                  how='left',\n",
    "                  left_on='cellId',\n",
    "                  right_on='cellId')\n",
    "    \n",
    "    labels[key] = lf\n",
    "    \n",
    "    rnaPath = f\"{cardDir}{key}_macrophage_rna.csv\"\n",
    "    rf = pd.read_csv(rnaPath)\n",
    "    rf = rf.T\n",
    "    new_header = rf.iloc[0] \n",
    "    rf = rf[1:] \n",
    "    rf.columns = new_header \n",
    "    rf.index.names = ['cellId']\n",
    "    \n",
    "    rf = ut.normalize(rf, 1e6)\n",
    "    \n",
    "    rna[key] = rf\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15205b57-339a-4b8a-87b9-3e1a01a97dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "cardOutDir = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/CARDOuputs/\"\n",
    "\n",
    "dfList = []\n",
    "\n",
    "for f in os.listdir(cardOutDir):\n",
    "    if 'macrophage' in f:\n",
    "        fullPath = f\"{cardOutDir}{f}\"\n",
    "        key = f.split(\"_\")[0]\n",
    "        df = pd.read_csv(fullPath)\n",
    "        df = df.rename(columns={'Unnamed: 0' : 'spotId'})\n",
    "        df['key'] = key\n",
    "        dfList.append(df)\n",
    "\n",
    "df = pd.concat(dfList, ignore_index=True)\n",
    "print(f\"{df.shape=}\")\n",
    "print(df['key'].value_counts())\n",
    "print()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a5f75-8217-4d4d-a942-25d687b6916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sptDir =  \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/CARDInputs/\"\n",
    "\n",
    "normalize = True\n",
    "\n",
    "spt = {}\n",
    "\n",
    "for f in os.listdir(sptDir):\n",
    "    if \"spt\" in f and \"macrophage\" in f:\n",
    "        print(f)\n",
    "        fullPath = f\"{sptDir}{f}\"\n",
    "        key = f.split(\"_\")[0]\n",
    "        sdf = pd.read_csv(fullPath)\n",
    "        sdf = sdf.rename(columns={'Unnamed: 0' : 'gene'})\n",
    "        sdf = sdf.set_index('gene')\n",
    "        sdf = sdf.T\n",
    "        sdf.index = sdf.index.str.replace(\"-\", \".\")\n",
    "        if normalize:\n",
    "            sdf = ut.normalize(sdf)\n",
    "        spt[key] = sdf\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439ca14c-14e1-41c8-82e0-1c5c1bdeec74",
   "metadata": {},
   "outputs": [],
   "source": [
    "coordDir = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/CARDInputs/\"\n",
    "\n",
    "dfList = []\n",
    "\n",
    "for f in os.listdir(coordDir):\n",
    "    if \"coord\" in f:\n",
    "        fullPath = f\"{coordDir}{f}\"\n",
    "        key = f.split(\"_\")[0]\n",
    "        cdf = pd.read_csv(fullPath)\n",
    "        cdf = cdf.rename(columns={'Unnamed: 0' : 'spotId'})\n",
    "        cdf['key'] = key\n",
    "        dfList.append(cdf)\n",
    "\n",
    "cdf = pd.concat(dfList, ignore_index=True)\n",
    "print(f\"{cdf.shape=}\")\n",
    "print(cdf['key'].value_counts())\n",
    "print()\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee511e6-bbc3-42d0-8e26-e8b4768abcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge CARD predictions with spatial coordinates\"\"\"\n",
    "df = pd.merge(cdf, df,\n",
    "              how='left', \n",
    "              left_on=['spotId', 'key'],\n",
    "              right_on=['spotId', 'key'])\n",
    "\n",
    "df = df.fillna(0)\n",
    "df = df.drop_duplicates() # very important!\n",
    "print(df['key'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea54ec4-46db-4ae8-96b2-e51e6dd79e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_node(node, nodes, metric):\n",
    "    closest_index = distance.cdist([node], nodes, metric=metric).argmin()\n",
    "    return closest_index\n",
    "\n",
    "def getGraph(kdf, x, y, n=300, metric='minkowski', return_center=True):\n",
    "    \"\"\"A function to generate a graph of size n x n\n",
    "    around point (x, y) \"\"\"\n",
    "    \n",
    "    nodes = kdf[['x', 'y']]\n",
    "    centerInd = closest_node([x, y], nodes, metric)\n",
    "    \n",
    "      \n",
    "    # get the n points around that node\n",
    "    nbrs = NearestNeighbors(n_neighbors=n,  \n",
    "                            metric=metric, \n",
    "                            algorithm='ball_tree').fit(nodes)\n",
    "    distances, indices = nbrs.kneighbors(nodes)\n",
    "    \n",
    "    # create the subgraph\n",
    "    windowIndices = indices[centerInd]\n",
    "    mask = kdf.index.isin(windowIndices)\n",
    "    \n",
    "    center = kdf[mask].reset_index(drop=True)\n",
    "    dists = sklearn.metrics.pairwise_distances(center[['x', 'y']], metric=metric)\n",
    "    \n",
    "    X = dists\n",
    "    \n",
    "    # create the graph\n",
    "    nodeMapper = dict(zip(center.index, center['spotId']))\n",
    "    G = nx.from_numpy_array(X)\n",
    "    G = nx.relabel_nodes(G, nodeMapper)\n",
    "    \n",
    "    # set positions\n",
    "    pos = {}\n",
    "    for idx, row in center.iterrows():\n",
    "        pos[row['spotId']] = np.array(row[['x', 'y']])\n",
    "    \n",
    "    G.pos = pos\n",
    "    \n",
    "    if return_center:\n",
    "        return G, center\n",
    "    else:\n",
    "        return G\n",
    "    \n",
    "    \n",
    "def getKnn(kdf, k=6, metric='minkowski'):\n",
    "    \"\"\"A function to generate a knn graph \"\"\"\n",
    "    \n",
    "    nodes = kdf[['x', 'y']]\n",
    "      \n",
    "    # get the n points around that node\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1,  \n",
    "                            metric=metric, \n",
    "                            algorithm='ball_tree').fit(nodes)\n",
    "    distances, indices = nbrs.kneighbors(nodes)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def knnInd2Id(kdf, knnInd):\n",
    "    \"\"\"Translate neighbors to spotIds \"\"\"\n",
    "    \n",
    "    transId = {}\n",
    "    \n",
    "    for i, row in kdf.iterrows():\n",
    "        spotId = row['spotId']\n",
    "        nbrhs = kdf.iloc[knnInd[i]]['spotId'].values\n",
    "        transId[spotId] = nbrhs\n",
    "    return transId\n",
    "    \n",
    "    \n",
    "\n",
    "def blur(sdf, transId):\n",
    "    \"\"\"A function to blur all columns using their neighbors.\n",
    "    Expects spotIds as index \"\"\"\n",
    "    \n",
    "    results  = []\n",
    "    \n",
    "    for spotId, nbhs in transId.items():\n",
    "        \n",
    "        t = sdf.loc[nbhs].mean().to_dict()\n",
    "        t['spotId'] = spotId\n",
    "        results.append(t)\n",
    "        \n",
    "    results = pd.DataFrame(results)\n",
    "    results = results.set_index('spotId')\n",
    "    return results\n",
    "\n",
    "\n",
    "def getCentralities(G):\n",
    "    \"\"\" function to compute centralities \"\"\"\n",
    "    cf = pd.DataFrame({'spotId' : G.nodes()})\n",
    "    cf['degree_centrality'] = cf['spotId'].map(nx.degree_centrality(G))\n",
    "    cf['betweenness_centrality'] = cf['spotId'].map(nx.betweenness_centrality(G))\n",
    "    cf['closeness_centrality'] = cf['spotId'].map(nx.closeness_centrality(G))\n",
    "    cf['harmonic_centrality'] = cf['spotId'].map(nx.harmonic_centrality(G))\n",
    "    cf['harmonic_centrality'] = cf['spotId'].map(nx.harmonic_centrality(G))\n",
    "    cf['eigenvector_centrality'] = cf['spotId'].map(nx.eigenvector_centrality(G, tol=0.001))\n",
    "    return cf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87370a9e-79d8-4877-96d9-f3c3cec7d35a",
   "metadata": {},
   "source": [
    "# quick viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84d16ce-2a4e-4a8e-8133-06b8f441cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key = \"HFD14\"\n",
    "# field = \"Mac5\" # the column to define edgeweights\n",
    "# networkSize = 150\n",
    "\n",
    "# edgeRadius = 25 # distance between spots\n",
    "# sampleSigma = 0.1 # variance around the center of the image\n",
    "# edgeThresh = 0.6\n",
    "\n",
    "# kdf = df[df['key'] == key].reset_index(drop=True)\n",
    "\n",
    "# # sample = kdf.sample(1)\n",
    "# sample = kdf[kdf['spotId'] == 'CTCCTCCAGCTCACAC.1']\n",
    "# print(f\"{sample['spotId'].values=}\")\n",
    "# sx = sample['x'].values[0]\n",
    "# sy = sample['y'].values[0]\n",
    "\n",
    "# # generate the graph \n",
    "# G, mf = getGraph(kdf, sx, sy, networkSize)\n",
    "# node_attr = mf.set_index('spotId').to_dict('index')\n",
    "# nx.set_node_attributes(G, node_attr)    \n",
    "\n",
    "# # define connections\n",
    "# edgelist = []\n",
    "# for u,v,e in G.edges(data=True):\n",
    "#     if e['weight'] < edgeRadius:\n",
    "#         x1 = G.nodes[u][field]\n",
    "#         x2 = G.nodes[v][field]\n",
    "\n",
    "#         mean = scipy.stats.hmean([x1, x2])\n",
    "#         # mean = np.mean([x1, x2])\n",
    "#         if mean > edgeThresh:\n",
    "#             edgelist.append((u, v, mean))\n",
    "\n",
    "# # build the new graph based on connections\n",
    "# H = nx.Graph()\n",
    "# H.add_nodes_from(G.nodes())\n",
    "# H.add_weighted_edges_from(edgelist)\n",
    "# H.pos = G.pos \n",
    "\n",
    "# # add centralities\n",
    "# cf = getCentralities(H)\n",
    "\n",
    "# node_attr = cf.set_index('spotId').to_dict('index')\n",
    "# nx.set_node_attributes(H, node_attr)    \n",
    "\n",
    "# mf = pd.merge(mf, cf, \n",
    "#               left_on='spotId', \n",
    "#               right_on='spotId', \n",
    "#               how='left')\n",
    "\n",
    "# components = sorted(nx.connected_components(H), key=len, reverse=True)\n",
    "# cc = H.subgraph(components[0]).copy()\n",
    "# original_nodes = list(cc.nodes())\n",
    "# print(f\"{nx.number_of_nodes(cc)=} (before)\")\n",
    "\n",
    "# neighbor_nodes = []\n",
    "\n",
    "# # add the neighbors\n",
    "# for node in cc.nodes():\n",
    "    \n",
    "#     # get edges in original graph\n",
    "#     for u,v,e in G.edges(node, data=True):\n",
    "#         if e['weight'] < edgeRadius:\n",
    "#             neighbor_nodes.append(u)\n",
    "#             neighbor_nodes.append(v)\n",
    "\n",
    "                \n",
    "# neighbor_nodes = list(set(neighbor_nodes))\n",
    "# cc.add_nodes_from(neighbor_nodes)\n",
    "# cc.pos = H.pos\n",
    "\n",
    "# print(f\"{nx.number_of_nodes(cc)=} (after)\")\n",
    "\n",
    "# plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams['figure.facecolor'] = \"w\"\n",
    "# plt.rcParams['figure.figsize'] = 3.5, 3.5\n",
    "\n",
    "# node_colors = ['orangered' for x in cc.nodes()]\n",
    "\n",
    "# node_colors = []\n",
    "\n",
    "# for n in cc.nodes():\n",
    "#     if n in original_nodes:\n",
    "#         node_colors.append(\"orangered\")\n",
    "#     else:\n",
    "#         node_colors.append(\"C0\")\n",
    "        \n",
    "# print(node_colors)\n",
    "\n",
    "# # node_colors = [v for k, v in nx.eigenvector_centrality(cc).items()]\n",
    "# # cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"w\", \"yellow\",\n",
    "# #                                                                 \"orangered\"])\n",
    "\n",
    "# # node_colors = np.random.random(len(cc.nodes()))\n",
    "\n",
    "# nx.draw(cc,\n",
    "#         cc.pos,\n",
    "#         edge_color=\"k\",\n",
    "#         edgecolors='k',\n",
    "#         linewidths=1.5,\n",
    "#         node_color=node_colors,\n",
    "#         # cmap=cmap,\n",
    "#         width=2,\n",
    "#         node_size=350)\n",
    "\n",
    "\n",
    "\n",
    "# plt.gca().set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ec02b9-98ff-41e3-8a54-7e07337496cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"w\", \"yellow\",\n",
    "#                                                                 \"orangered\"])\n",
    "\n",
    "# ut.makeColorbar('viridis', 0.3, 2, 'Expression', 'vertical', [\"Low\", \"High\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b40108-ae9f-4476-ba94-4afd83d3c133",
   "metadata": {},
   "source": [
    "# build samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4d9b24-4c52-4163-8b89-f896435c1f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling networks \n",
    "\n",
    "keys = ['ND', 'HFD8', 'HFD14']\n",
    "\n",
    "field = \"Monocytes\" # the column to define edgeweights\n",
    "networkSize = 150\n",
    "nNetworks = 200 # from each time point\n",
    "edgeRadius = 25 # distance between spots\n",
    "sampleSigma = 0.1 # variance around the center of the image\n",
    "edgeThresh = 0.15\n",
    "\n",
    "graph = {}\n",
    "meta = {}\n",
    "deets = {}\n",
    "\n",
    "keyInds = np.random.choice(list(range(len(keys))), nNetworks, replace=True)\n",
    "\n",
    "for i, key in enumerate(keys):\n",
    "\n",
    "    kdf = df[df['key'] == key].reset_index(drop=True)\n",
    "    \n",
    "    for s in range(nNetworks):\n",
    "        sample = kdf.sample(1)\n",
    "        sx = sample['x'].values[0]\n",
    "        sy = sample['y'].values[0]\n",
    "    \n",
    "        # generate the graph \n",
    "        G, mf = getGraph(kdf, sx, sy, networkSize)\n",
    "\n",
    "        # # define the node properties\n",
    "        # mf['norm'] = mf['Mac5'] / mf['Mac5'].max()\n",
    "\n",
    "        node_attr = mf.set_index('spotId').to_dict('index')\n",
    "        nx.set_node_attributes(G, node_attr)    \n",
    "\n",
    "        # define connections\n",
    "        edgelist = []\n",
    "        for u,v,e in G.edges(data=True):\n",
    "            if e['weight'] < edgeRadius:\n",
    "                x1 = G.nodes[u][field]\n",
    "                x2 = G.nodes[v][field]\n",
    "\n",
    "                mean = scipy.stats.hmean([x1, x2])\n",
    "                # mean = np.mean([x1, x2])\n",
    "                # if mean > edgeThresh:\n",
    "                edgelist.append((u, v, mean))\n",
    "\n",
    "        # build the new graph based on connections\n",
    "        H = nx.Graph()\n",
    "        H.add_nodes_from(G.nodes())\n",
    "        H.add_weighted_edges_from(edgelist)\n",
    "        H.pos = G.pos \n",
    "\n",
    "        # add centralities\n",
    "        cf = getCentralities(H)\n",
    "\n",
    "        node_attr = cf.set_index('spotId').to_dict('index')\n",
    "        nx.set_node_attributes(H, node_attr)    \n",
    "\n",
    "        mf = pd.merge(mf, cf, \n",
    "                      left_on='spotId', \n",
    "                      right_on='spotId', \n",
    "                      how='left')\n",
    "\n",
    "        graph[key, s] = H\n",
    "        meta[key, s] = mf\n",
    "        deets[key, s] = {\n",
    "            'key' : key,\n",
    "            'x' : sx,\n",
    "            'y' : sy,\n",
    "        }\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6927eb70-3794-4f38-a107-de8c6141c6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors = [\n",
    "#     '#9835e4',\n",
    "#     '#e48035',\n",
    "#     '#8e0152',\n",
    "#     '#9acd61',\n",
    "#     '#276419',\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c679b6-8ccc-4ffb-a055-1611f05536c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = \"w\"\n",
    "plt.rcParams['figure.figsize'] = 9, 9\n",
    "\n",
    "plotBox = 300\n",
    "\n",
    "fig, axs = plt.subplots(3, 3)\n",
    "axs = axs.ravel()\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"lightgrey\", \n",
    "                                                                \"gold\", \n",
    "                                                                \"orange\", \n",
    "                                                                \"orangered\",\n",
    "                                                                \"firebrick\"])\n",
    "\n",
    "plotI = 0\n",
    "\n",
    "\n",
    "details = pd.DataFrame.from_dict(deets, orient='index')\n",
    "\n",
    "sampleList = []\n",
    "\n",
    "for key in keys:\n",
    "    tosample = details[details['key'] == key].sample(3)\n",
    "    sampleList += tosample.index.to_list()\n",
    "    \n",
    "\n",
    "for i in sampleList:\n",
    "    key = deets[i]['key']\n",
    "    G = graph[i]\n",
    "    mf = meta[i]\n",
    "    \n",
    "    node_color = mf['degree_centrality'].to_list()\n",
    "    \n",
    "    nx.draw(G, G.pos,\n",
    "            with_labels=False,\n",
    "            ax=axs[plotI], \n",
    "            node_color=node_color,\n",
    "            edge_color=\"k\",\n",
    "            edgecolors='k',\n",
    "            # vmin=0,\n",
    "            # vmax=0.2,\n",
    "            linewidths=1,\n",
    "            width=2,\n",
    "            cmap=cmap,\n",
    "            node_size=50)\n",
    "    \n",
    "    \n",
    "    \n",
    "    img = lowres[key]\n",
    "    axs[plotI].imshow(img, \n",
    "                      cmap='binary_r',\n",
    "                      alpha=0.6,\n",
    "                      zorder=0)\n",
    "    \n",
    "    kdf = df[df['key'] == key].reset_index(drop=True)\n",
    "    \n",
    "    # get the center node index\n",
    "    xMid = deets[i]['x']\n",
    "    yMid = deets[i]['y']\n",
    "    \n",
    "    xLb = int(xMid - (plotBox / 2))\n",
    "    xUb = int(xMid + (plotBox / 2))\n",
    "    \n",
    "    yLb = int(yMid - (plotBox / 2))\n",
    "    yUb = int(yMid + (plotBox / 2))\n",
    "\n",
    "    axs[plotI].set_ylim([yUb, yLb])\n",
    "    axs[plotI].set_xlim([xLb, xUb])    \n",
    "    # axs[plotI].set_title(key)\n",
    "    axs[plotI].set_xticks([])\n",
    "    axs[plotI].set_yticks([])    \n",
    "    \n",
    "    if plotI == 6:\n",
    "    \n",
    "        microns = 100\n",
    "        sbarHires = getscalebar(key, microns)\n",
    "\n",
    "        scalebar = AnchoredSizeBar(axs[plotI].transData,\n",
    "                               sbarHires, \n",
    "                               f'{microns}' + r'$\\mu m$', \n",
    "                               loc='lower left', \n",
    "                               # pad=0.2,\n",
    "                               color='k',\n",
    "                               frameon=False,\n",
    "                               size_vertical=1,\n",
    "                               zorder=10,\n",
    "                               bbox_to_anchor=(0.5, 0.5, 0, 0),\n",
    "                               fontproperties={'size':8})\n",
    "        \n",
    "        axs[plotI].add_artist(scalebar)\n",
    "    \n",
    "    plotI += 1\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aff45e0-6191-4e95-91cc-df5ccd591ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data\n",
    "tmp = []\n",
    "\n",
    "sampleNum = 0\n",
    "for i in sampleList:\n",
    "    sampleNum += 1\n",
    "    mf = meta[i]\n",
    "    mf['sample'] = f\"sample_{sampleNum}\"\n",
    "\n",
    "\n",
    "    tmp.append(mf)\n",
    "\n",
    "\n",
    "tmp = pd.concat(tmp)\n",
    "\n",
    "outdir = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/FIGURE_DATA/FIG5/\"\n",
    "fname = \"random_networks.csv\"\n",
    "tmp.to_csv(f\"{outdir}{fname}\", index=False)\n",
    "tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7858732-75eb-44e2-bb39-e1d566510966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e14d12-201b-4c86-bf65-91997bcd483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab21aa4-8a81-4bf1-a968-178403bb4cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ut.makeColorbar(cmap, 0.3, 2, 'Degree', 'vertical', [\"Low\", \"High\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b67828-e70c-4d82-b498-5578ba771550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # edge distribution\n",
    "# res = []\n",
    "\n",
    "# for (key, num), G in graph.items():\n",
    "    \n",
    "#     mean_eweight = np.mean([e['weight'] for u, v, e in G.edges(data=True)])\n",
    "    \n",
    "#     row = {\n",
    "#         'key' : key,\n",
    "#         'num' : num,\n",
    "#         'mean_eweight' : mean_eweight,\n",
    "#         'nodes' : nx.number_of_nodes(G),\n",
    "#         'e2n' :   nx.number_of_edges(G) / nx.number_of_nodes(G)}\n",
    "    \n",
    "#     res.append(row)\n",
    "    \n",
    "    \n",
    "# res = pd.DataFrame(res)\n",
    "\n",
    "# keyMap = {\n",
    "#     'ND' : 'ND',\n",
    "#     'HFD8' : '8w',\n",
    "#     'HFD14' : '14w',\n",
    "# }\n",
    "\n",
    "# res['keyName'] = res['key'].map(keyMap)\n",
    "\n",
    "# plt.rcParams['figure.dpi'] = 300\n",
    "# plt.rcParams['figure.facecolor'] = \"w\"\n",
    "# plt.rcParams['figure.figsize'] = 4, 2\n",
    "\n",
    "# sns.histplot(data=res, \n",
    "#              x='mean_eweight',\n",
    "#              bins=30,\n",
    "#              hue='keyName',\n",
    "#              # legend=False,\n",
    "#              palette='viridis')\n",
    "\n",
    "# sns.despine()\n",
    "# plt.gca().legend().remove()\n",
    "\n",
    "# # sns.move_legend(plt.gca(), \n",
    "# #                 \"upper right\", \n",
    "# #                 title='',\n",
    "# #                 frameon=False,)\n",
    "# plt.ylabel(\"Number of Networks\")\n",
    "# # plt.xlabel(\"Mean Edge Weight\")\n",
    "# plt.xlabel(\"Mac5 Connectivity\")\n",
    "# plt.title('Mac5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2852e9d1-5817-433f-93b1-04bcb638d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge distribution\n",
    "pdf = []\n",
    "\n",
    "for (key, num), G in graph.items():\n",
    "    \n",
    "    mean_eweight = np.mean([e['weight'] for u, v, e in G.edges(data=True)])\n",
    "    \n",
    "    row = {\n",
    "        'key' : key,\n",
    "        'num' : num,\n",
    "        'mean_eweight' : mean_eweight,\n",
    "        'nodes' : nx.number_of_nodes(G),\n",
    "        'e2n' :   nx.number_of_edges(G) / nx.number_of_nodes(G)}\n",
    "    \n",
    "    pdf.append(row)\n",
    "    \n",
    "    \n",
    "pdf = pd.DataFrame(pdf)\n",
    "\n",
    "keyMap = {\n",
    "    'ND' : 'ND',\n",
    "    'HFD8' : '8w',\n",
    "    'HFD14' : '14w',\n",
    "}\n",
    "\n",
    "pdf['keyName'] = pdf['key'].map(keyMap)\n",
    "\n",
    "\n",
    "g = sns.FacetGrid(pdf, \n",
    "                  row=\"keyName\", \n",
    "                  hue=\"key\", \n",
    "                  height=1, \n",
    "                  aspect=4,\n",
    "                  palette='viridis')\n",
    "\n",
    "# Draw the densities in a few steps\n",
    "g.map(sns.kdeplot, \"mean_eweight\",\n",
    "      bw_adjust=.5, \n",
    "      clip_on=True,\n",
    "      common_norm=False,\n",
    "      fill=True, \n",
    "      log_scale=True,\n",
    "      alpha=0.8, \n",
    "      linewidth=1.5)\n",
    "\n",
    "\n",
    "g.set_titles(\"\")\n",
    "g.set(ylabel=\"\")\n",
    "\n",
    "g.despine(bottom=False, \n",
    "          right=True,\n",
    "          left=True)\n",
    "\n",
    "for ax, label in zip(g.axes.flat, pdf['keyName'].unique()):\n",
    "    ax.text(0.0, 0.5, label, \n",
    "            fontsize=12,\n",
    "            ha=\"left\", \n",
    "            va=\"center\", \n",
    "            transform=ax.transAxes)\n",
    "\n",
    "# plt.xlabel(\"Mac5 Connectivity\")\n",
    "plt.xlabel(\"\")\n",
    "plt.suptitle('Monocyte')\n",
    "plt.tight_layout()\n",
    "fig = plt.gcf()\n",
    "_ = plt.xticks([pdf['mean_eweight'].min(), pdf['mean_eweight'].max()], \n",
    "           ['Less Connected', 'More Connected'])\n",
    "_ = plt.yticks([])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae259a0f-3cde-4056-bdc4-845ba99c0f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85a676-024b-4d1f-9cfc-6999793d1838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholdEdges(G, t):\n",
    "    \"\"\" Remove all edges with weight<T from G or its copy. \"\"\"\n",
    "    F = G.copy()\n",
    "    F.remove_edges_from([(u, v) for u, v, e in F.edges(data=\"weight\") if e < t])\n",
    "    return F\n",
    "\n",
    "t = 0.15\n",
    "\n",
    "res = []\n",
    "\n",
    "for (key, num), G in graph.items():\n",
    "    F = thresholdEdges(G, t)\n",
    "    \n",
    "    degree = [d for n, d in F.degree]\n",
    "    meanDegree = np.mean(degree)\n",
    "    \n",
    "    \n",
    "    components = sorted(nx.connected_components(F), key=len, reverse=True)\n",
    "    nComp = len(components)\n",
    "    sizeLargest = len(components[0])    \n",
    "    \n",
    "    row = {\n",
    "        'key' : key,\n",
    "        'num' : num,\n",
    "        'nComp' : nComp,\n",
    "        'edges' : nx.number_of_edges(F),\n",
    "        'sizeLargest' : sizeLargest,\n",
    "        'meanDegree' : meanDegree,\n",
    "    }\n",
    "    \n",
    "    res.append(row)\n",
    "    \n",
    "    \n",
    "res = pd.DataFrame(res)\n",
    "res.head()\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = \"w\"\n",
    "plt.rcParams['figure.figsize'] = 4, 2\n",
    "\n",
    "sns.histplot(data=res, \n",
    "             x='meanDegree',\n",
    "             bins=50,\n",
    "             hue='key',\n",
    "             # legend=False,\n",
    "             palette='viridis')\n",
    "\n",
    "sns.despine()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "sns.move_legend(plt.gca(), \"upper right\", title='')\n",
    "plt.ylabel(\"Number of Networks\")\n",
    "plt.xlabel(\"Average Degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fab175-e42b-4811-a994-5af747a8c344",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = \"w\"\n",
    "plt.rcParams['figure.figsize'] = 4, 3.5\n",
    "sns.scatterplot(data=res, \n",
    "             x='meanDegree',\n",
    "             y='sizeLargest',\n",
    "             hue='key',\n",
    "             ec='None',\n",
    "             alpha=0.5,\n",
    "             # legend=False,\n",
    "             palette='viridis')\n",
    "\n",
    "sns.despine()\n",
    "# plt.legend(loc='upper right')\n",
    "\n",
    "sns.move_legend(plt.gca(), \"lower right\", title='')\n",
    "plt.ylabel(\"Largest Connected Component\")\n",
    "plt.xlabel(\"Average Degree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2f207-7d0e-4c6d-a6ab-d4ff26b0b267",
   "metadata": {},
   "outputs": [],
   "source": [
    " # components = sorted(nx.connected_components(F), key=len, reverse=True)\n",
    "#     sizeLargest = len(components[0])    \n",
    "    \n",
    "#     fiedler = 0.0\n",
    "#     if sizeLargest > 10:\n",
    "        \n",
    "#         cc = G.subgraph(components[0])\n",
    "        \n",
    "#         # get normalized laplacian\n",
    "#         A = nx.adjacency_matrix(cc).todense()\n",
    "    \n",
    "\n",
    "#         L = csgraph.laplacian(A, normed=True, symmetrized=True)\n",
    "#         evals, evecs = np.linalg.eigh(L)\n",
    "#         fiedler = evals[1]\n",
    "#         fiedler = fiedler * A.shape[0]\n",
    "\n",
    "#     row = {\n",
    "#         'key' : key,\n",
    "#         'num' : num,\n",
    "#         'density' : nx.density(F),\n",
    "#         'clustering' : nx.average_clustering(F),\n",
    "#     }\n",
    "    \n",
    "#     res.append(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c6005-3976-4495-aa35-3460c3208eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholdEdges(G, t):\n",
    "    \"\"\" Remove all edges with weight<T from G or its copy. \"\"\"\n",
    "    F = G.copy()\n",
    "    F.remove_edges_from([(u, v) for u, v, e in F.edges(data=\"weight\") if e < t])\n",
    "    return F\n",
    "\n",
    "\n",
    "def getOHT(A):\n",
    "    u, s, vh = np.linalg.svd(A)\n",
    "    m = u.shape[0]\n",
    "    n = vh.shape[0] \n",
    "    beta = m / n\n",
    "    omega = (0.56*beta**3) - (0.95 * beta**2) + (1.82 * beta) + 1.43\n",
    "    y_med = np.median(s)\n",
    "    tau = omega * y_med\n",
    "    s_ind = np.argwhere(s >= tau)\n",
    "    oht = np.max(s_ind) \n",
    "    return oht\n",
    "\n",
    "t = 0.15\n",
    "res = []\n",
    "\n",
    "for (key, num), G in graph.items():\n",
    "    F = thresholdEdges(G, t)\n",
    "    A = nx.adjacency_matrix(F).todense()\n",
    "    rank = np.linalg.matrix_rank(A)\n",
    "    oht = getOHT(A)\n",
    "\n",
    "    row = {\n",
    "        'key' : key,\n",
    "        'num' : num,\n",
    "        'rank' : rank,\n",
    "        'oht' : oht,\n",
    "        'clustering' : nx.average_clustering(F),\n",
    "    }\n",
    "    \n",
    "    res.append(row)\n",
    "    \n",
    "res = pd.DataFrame(res)\n",
    "res = res.fillna(0)\n",
    "res['oht'] = np.where(res['oht'] == 149, 0, res['oht']) # handle the zero-matrices\n",
    "\n",
    "res.head()\n",
    "\n",
    "sns.scatterplot(data=res, \n",
    "                x='oht',\n",
    "                y='clustering',\n",
    "                ec='None',\n",
    "                hue='key',\n",
    "                alpha=0.5,\n",
    "                palette='viridis')\n",
    "\n",
    "sns.despine()\n",
    "sns.move_legend(plt.gca(), \"upper right\", title='')\n",
    "plt.ylabel(\"Clustering Coefficient\")\n",
    "plt.xlabel(\"Optimal Hard Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b6de30-8a09-4a00-b02d-c91fd4d6c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb0931f-6394-4b73-839d-375d067a0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"/nfs/turbo/umms-indikar/shared/projects/spatial_transcriptomics/data/FIGURE_DATA/SUPP/\"\n",
    "fname = \"optimal_hard_threshold.csv\"\n",
    "res.to_csv(f\"{outdir}{fname}\", index=False)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09012da1-6a98-4117-946b-29204e80460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a89dd7a-dccf-4103-a7e4-e5e423ed35e8",
   "metadata": {},
   "source": [
    "# DEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad64169-ee64-4c20-a086-38c6804a4e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def thresholdEdges(G, t):\n",
    "    \"\"\" Remove all edges with weight<T from G or its copy. \"\"\"\n",
    "    F = G.copy()\n",
    "    F.remove_edges_from([(u, v) for u, v, e in F.edges(data=\"weight\") if e < t])\n",
    "    return F\n",
    "\n",
    "t = 0.055\n",
    "\n",
    "res = []\n",
    "\n",
    "for (key, num), G in graph.items():\n",
    "    if not key in ['HFD8', 'HFD14']:\n",
    "        continue\n",
    "        \n",
    "    F = thresholdEdges(G, t)\n",
    "    edges = F.edges()\n",
    "    inNodes = list(set(sum(edges, ())))\n",
    "    outNodes = [x for x in G.nodes() if not x in inNodes]\n",
    "    \n",
    "    nf = pd.DataFrame({\n",
    "        'node' : inNodes,\n",
    "    })\n",
    "    \n",
    "    nf['type'] = 'connected'\n",
    "    nf['key'] = key\n",
    "    res.append(nf) # add connected nodes\n",
    "        \n",
    "    \n",
    "    nf = pd.DataFrame({\n",
    "        'node' : outNodes,\n",
    "    })\n",
    "    \n",
    "    nf['type'] = 'disconnected'\n",
    "    nf['key'] = key\n",
    "    res.append(nf) # add disconnected nodes\n",
    "    \n",
    "cdf = pd.concat(res)\n",
    "print(f\"{cdf.shape=}\")\n",
    "cdf = cdf.drop_duplicates(subset=['node', 'key'])\n",
    "print(f\"{cdf.shape=}\")\n",
    "print()\n",
    "print(cdf['key'].value_counts())\n",
    "print()\n",
    "print(cdf['type'].value_counts())\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d19c9-6922-4c94-9ae2-8f519dca9470",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "for key in cdf['key'].unique():\n",
    "    sdf = spt[key]\n",
    "    \n",
    "    rdf = cdf[cdf['key'] == key]\n",
    "    mask = rdf['type'] == 'connected'\n",
    "    \n",
    "    inNodes = rdf[mask]['node'].to_list()\n",
    "    outNodes = rdf[~mask]['node'].to_list()\n",
    "    \n",
    "    inNet = sdf[sdf.index.isin(inNodes)]\n",
    "    outNet = sdf[sdf.index.isin(outNodes)]\n",
    "    \n",
    "    for gene in sdf.columns:\n",
    "        \n",
    "        score, pval = scipy.stats.ranksums(inNet[gene], \n",
    "                                           outNet[gene],\n",
    "                                           alternative='two-sided')\n",
    "        imean = inNet[gene].mean()\n",
    "        omean = outNet[gene].mean()\n",
    "        \n",
    "        lfc = np.log2(imean + 0.001) - np.log2(omean + 0.001)\n",
    "        \n",
    "        row = {\n",
    "            'gene' : gene,\n",
    "            'key' : key,\n",
    "            'score' : score,\n",
    "            'pval' : pval,\n",
    "            'log2foldchange' : lfc,\n",
    "            'meaninNet' : imean,\n",
    "            'meanoutNet' : omean,\n",
    "        }\n",
    "        \n",
    "        res.append(row)\n",
    "    \n",
    "res = pd.DataFrame(res)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d75fea-3e5b-44ac-a679-e9bd4d8044a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n = 2\n",
    "\n",
    "ntests = len(sdf.columns)\n",
    "alphaHat = 1 - ((1-alpha) ** (1/ntests))\n",
    "print(f\"{alpha=} {ntests=} {alphaHat}\")\n",
    "\n",
    "sig = res[res['pval'] < alphaHat]\n",
    "print(sig.shape)\n",
    "sig['key'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e87973-2d8f-4804-90ee-6326d88e84e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = sig['gene'].to_list()\n",
    "\n",
    "# db = 'WikiPathways_2019_Mouse'\n",
    "db = 'KEGG_2019_Mouse'\n",
    "# db = 'ontology'\n",
    "ef = gget.enrichr(genes, database=db)\n",
    "\n",
    "pdf = ef[['path_name', 'adj_p_val']].reset_index()\n",
    "pdf['logp'] = pdf['adj_p_val'].apply(lambda x: -np.log10(x))\n",
    "\n",
    "pdf['pname'] = [ '\\n'.join(wrap(l, 40)) for l in pdf['path_name']]\n",
    "pdf['pname'] = pdf['pname'].str.replace(\"processing and \", \"\")\n",
    "pdf['pname'] = pdf['pname'].str.replace(\"pathway\", \"\")\n",
    "pdf['pname'] = pdf['pname'].str.replace(\"in cancer\", \"\")\n",
    "\n",
    "pdf.head()\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = \"w\"\n",
    "plt.rcParams['figure.figsize'] = 2, 2\n",
    "\n",
    "sns.barplot(data=pdf.head(10),\n",
    "            x='logp',\n",
    "            y='pname',\n",
    "            color='lightgrey',\n",
    "            edgecolor='k')\n",
    "\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"p-value (log10)\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='y', which='major', labelsize=8)\n",
    "\n",
    "sns.despine()\n",
    "ef.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142bfd75-d48d-4ff8-a731-843251be61d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670676b-2cd9-4e32-a984-45ad025c4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = ef['overlapping_genes'].head(10).to_list()\n",
    "genes = list(itertools.chain(*genes))\n",
    "\n",
    "\", \".join([x[0].lower().title() for x in Counter(genes).most_common(5)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b56f05-e886-467c-8a07-90c8bd3eda65",
   "metadata": {},
   "source": [
    "# DEG and network centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dd2767-c223-47db-8f92-5a4638e03159",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0.1\n",
    "res = []\n",
    "\n",
    "for (key, num), G in graph.items():\n",
    "    F = thresholdEdges(G, t)\n",
    "    \n",
    "    sub = pd.DataFrame({\n",
    "        'spotId': G.nodes(),\n",
    "    })\n",
    "    sub['key'] = key\n",
    "    sub['graphId'] = num\n",
    "\n",
    "    sub['degree_centrality'] = sub['spotId'].map(nx.degree_centrality(F))\n",
    "    sub['eigenvector_centrality'] = sub['spotId'].map(nx.eigenvector_centrality(F, weight='weight', tol=1e-02))\n",
    "    sub['closeness_centrality'] = sub['spotId'].map(nx.closeness_centrality(F))\n",
    "    sub['betweenness_centrality'] = sub['spotId'].map(nx.betweenness_centrality(F, weight='weight'))\n",
    "    res.append(sub)\n",
    "    \n",
    "    \n",
    "res = pd.concat(res, ignore_index=True)\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fd3dc7-e51a-46f4-9f78-32fb14772b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = res.copy()\n",
    "\n",
    "centCols = ['degree_centrality']\n",
    "\n",
    "# ,[degree_centrality]\n",
    "#             'eigenvector_centrality',\n",
    "#             'closeness_centrality',\n",
    "#             'betweenness_centrality']\n",
    "\n",
    "# groupby max to account for the spot appearing in several samples\n",
    "pdf = pdf.groupby(['spotId', 'key'])[centCols].max().reset_index(drop=False)\n",
    "\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05447cb0-3e48-469a-831d-55b9392fdbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = []\n",
    "\n",
    "centTresh = 0.9\n",
    "\n",
    "for key in ['HFD8', 'HFD14']:\n",
    "    sdf = spt[key]\n",
    "    cdf = pdf[pdf['key'] == key].reset_index()\n",
    "    \n",
    "    # normalize the centralities\n",
    "    for c in centCols:\n",
    "        cdf[c] = (cdf[c] - cdf[c].min()) / (cdf[c].max() - cdf[c].min())\n",
    "        \n",
    "    # make an aggregate column\n",
    "    cdf['meanCent'] = cdf[centCols].apply(lambda x: scipy.stats.hmean(x), axis=1)\n",
    "    \n",
    "    # determine highly central nodes        \n",
    "    mask = (cdf['meanCent'] > centTresh)\n",
    "    inNodes = cdf[mask]['spotId'].to_list()\n",
    "    outNodes = cdf[~mask]['spotId'].to_list()\n",
    "    \n",
    "    print(f\"{key=} {len(inNodes)=} {len(outNodes)=}\")\n",
    "    \n",
    "    inNet = sdf[sdf.index.isin(inNodes)]\n",
    "    outNet = sdf[sdf.index.isin(outNodes)]\n",
    "    \n",
    "    # perform differential expression on highly central nodes\n",
    "    for gene in sdf.columns:\n",
    "        score, pval = scipy.stats.ranksums(inNet[gene], \n",
    "                                           outNet[gene],\n",
    "                                           alternative='two-sided')\n",
    "        imean = inNet[gene].mean()\n",
    "        omean = outNet[gene].mean()\n",
    "        \n",
    "        lfc = np.log2(imean + 0.001) - np.log2(omean + 0.001)\n",
    "        \n",
    "        row = {\n",
    "            'gene' : gene,\n",
    "            'key' : key,\n",
    "            'score' : score,\n",
    "            'pval' : pval,\n",
    "            'log2foldchange' : lfc,\n",
    "            'meaninNet' : imean,\n",
    "            'meanoutNet' : omean,\n",
    "        }\n",
    "        \n",
    "        deg.append(row)\n",
    "    \n",
    "deg = pd.DataFrame(deg)\n",
    "deg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36869b70-5717-4d2e-beb2-9e498f113d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "n = 2\n",
    "\n",
    "ntests = len(sdf.columns)\n",
    "alphaHat = 1 - ((1-alpha) ** (1/ntests))\n",
    "print(f\"{alpha=} {ntests=} {alphaHat}\")\n",
    "\n",
    "sig = deg[deg['pval'] < alpha]\n",
    "print(sig.shape)\n",
    "sig['key'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca69977-32ed-449e-ab62-c27ec11606d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = sig.sort_values(by='log2foldchange', ascending=False)\n",
    "\n",
    "n = 30\n",
    "genes = sig['gene'].head(n).to_list()\n",
    "\n",
    "# db = 'WikiPathways_2019_Mouse'\n",
    "db = 'KEGG_2019_Mouse'\n",
    "# db = 'ontology'\n",
    "ef = gget.enrichr(genes, database=db)\n",
    "\n",
    "pdf = ef[['path_name', 'adj_p_val']].reset_index()\n",
    "pdf['logp'] = pdf['adj_p_val'].apply(lambda x: -np.log10(x))\n",
    "\n",
    "pdf['pname'] = [ '\\n'.join(wrap(l, 40)) for l in pdf['path_name']]\n",
    "# pdf['pname'] = pdf['pname'].str.replace(\"processing and \", \"\")\n",
    "# pdf['pname'] = pdf['pname'].str.replace(\"pathway\", \"\")\n",
    "pdf['pname'] = pdf['pname'].str.replace(\"in cancer\", \"\")\n",
    "\n",
    "pdf.head()\n",
    "\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['figure.facecolor'] = \"w\"\n",
    "plt.rcParams['figure.figsize'] = 2, 4\n",
    "\n",
    "sns.barplot(data=pdf.head(10),\n",
    "            x='logp',\n",
    "            y='path_name',\n",
    "            color='lightgrey',\n",
    "            edgecolor='k')\n",
    "\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel(\"p-value (log10)\")\n",
    "ax = plt.gca()\n",
    "ax.tick_params(axis='x', which='major', labelsize=8)\n",
    "\n",
    "\n",
    "sns.despine()\n",
    "\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "ef[['path_name', 'adj_p_val', 'overlapping_genes']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e11b99-fb22-48a8-ae97-081f3c785ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9b00c4-a863-44b3-a295-767ea919ef62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be19908-21e0-4fd9-86d1-c403ba42651c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44429083-bdb6-498e-88f6-3dc1c6df610e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908cb627-5d15-4d16-99a8-4282fea036c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30896857-02e8-4530-8ffc-fa1b4708d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "\n",
    "t = pd.DataFrame({\n",
    "    'x1' : np.linspace(0, 1, n), \n",
    "    'x2' : np.linspace(0.5, 0.001, n),\n",
    "})\n",
    "\n",
    "t['mean'] = t.mean(axis=1)\n",
    "t['hmean'] = t[['x1', 'x2']].apply(lambda x: scipy.stats.hmean(x), axis=1)\n",
    "\n",
    "\n",
    "plt.plot(t['mean'], t['hmean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671bd778-f352-437f-b897-d09f45aead18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
